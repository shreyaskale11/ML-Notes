{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Gradient descent \n",
    "\n",
    "In linear regression, you utilize input training data to fit the parameters $w$,$b$ by minimizing a measure of the error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$. The measure is called the $cost$, $J(w,b)$. In training you measure the cost over all of our training samples $x^{(i)},y^{(i)}$\n",
    "\n",
    "$$ J_{w,b} = \\frac{1}{2m}\\sum\\limits_{i=1}^{m-1} (f_{w,b}(x^{(i)})  - y^{(i)})^2  $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "gradient descent defined as \n",
    "\n",
    "                                    repeat until converge {\n",
    "$$ w_{j} = w_{j} - \\alpha \\frac{\\partial J(w,b)}{\\partial w_{j}} \\; \\text{where n = 0..n-1} $$ \n",
    "$$ b = b - \\alpha \\frac{\\partial J(w,b)}{\\partial b} $$\n",
    "                                                        }\n",
    "\n",
    "if $\\frac{\\partial J(w,b)}{\\partial w}$ is slope when \n",
    "    +ve  -> w decreases (moves towards left) \n",
    "    -ve  -> w increases (moves towards right) \n",
    "\n",
    "the gradient descent is with gradient of cost w.r.t to w and b\n",
    "\n",
    "                                    repeat until converge {\n",
    "$$ w = w - \\alpha \\frac{1}{m}\\sum\\limits_{i=1}^{m-1} (f_{w,b}(x^{(i)})  - y^{(i)})(x_{j}^{(i)}) $$\n",
    "$$ b = b - \\alpha \\frac{1}{m}\\sum\\limits_{i=1}^{m-1} (f_{w,b}(x^{(i)})  - y^{(i)}) $$\n",
    "                                                        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 209314.1336159363\n",
      "100 671.6664448665141\n",
      "200 671.6661571235436\n",
      "300 671.6658693815885\n",
      "400 671.6655816406517\n",
      "500 671.6652939007305\n",
      "600 671.6650061618273\n",
      "700 671.6647184239407\n",
      "800 671.6644306870704\n",
      "900 671.6641429512182\n",
      "[ 0.2083132  -0.60111553 -0.18031452 -0.17953791] -0.0011102253224113373\n",
      "prediction: 427.02, target value: 460\n",
      "prediction: 285.62, target value: 232\n",
      "prediction: 169.82, target value: 178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def model_function(x,w,b):\n",
    "    return np.dot(x,w)+b\n",
    "\n",
    "def cost_function(x,y,w,b):\n",
    "    m = x.shape[0]\n",
    "    f_wb = model_function(x,w,b)\n",
    "    total_loss =  (np.sum((f_wb - y)**2))/(2*m)\n",
    "    return total_loss\n",
    "\n",
    "def compute_gradient(x,y,w,b):\n",
    "    m = x.shape[0]\n",
    "    f_wb = model_function(x,w,b)\n",
    "    dj_db = (1/m)*np.sum((f_wb - y))\n",
    "    dj_dw = (1/m)*np.sum(x.T*(f_wb - y))\n",
    "    return dj_dw,dj_db\n",
    "\n",
    "def compute_gradient_descent(x,y,w,b,alpha,iterations=100):\n",
    "    m = x.shape[0]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        dj_dw,dj_db = compute_gradient(x,y,w,b)\n",
    "\n",
    "        w = w - alpha *(1/m)* dj_dw\n",
    "        b = b - alpha *(1/m)* dj_db\n",
    "\n",
    "        if i%100==0:\n",
    "            print(i,cost_function(x,y,w,b))\n",
    "\n",
    "    return w,b\n",
    "\n",
    "\n",
    "X_train = np.array([[2104, 5, 1, 45], \n",
    "                    [1416, 3, 2, 40], \n",
    "                    [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "\n",
    "w = np.random.rand(X_train.shape[1])\n",
    "# w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "\n",
    "# w = np.zeros_like(w_init)\n",
    "b = 0\n",
    "alpha = 5.0e-7\n",
    "# dj_db,dj_dw = compute_gradient(x_train,y_train,w,b)\n",
    "w_n ,b_n = compute_gradient_descent(X_train,y_train,w,b,alpha,1000)\n",
    "print(w_n ,b_n)\n",
    "for i in range(X_train.shape[0]):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_n) + b_n:0.2f}, target value: {y_train[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "religion_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
